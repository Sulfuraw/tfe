game: tiny_bridge_2p(abstracted=true)

GameType.chance_mode = ChanceMode.EXPLICIT_STOCHASTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.IMPERFECT_INFORMATION
GameType.long_name = "Tiny Bridge (Uncontested)"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = ["abstracted"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = True
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "tiny_bridge_2p"
GameType.utility = Utility.IDENTICAL

NumDistinctActions() = 7
PolicyTensorShape() = [7]
MaxChanceOutcomes() = 28
GetParameters() = {abstracted=True}
NumPlayers() = 2
MinUtility() = -40.0
MaxUtility() = 35.0
UtilitySum() = None
InformationStateTensorShape() = [26]
InformationStateTensorLayout() = TensorLayout.CHW
InformationStateTensorSize() = 26
ObservationTensorShape() = [19]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 19
MaxGameLength() = 8
ToString() = "tiny_bridge_2p(abstracted=True)"

# State 0
# W:?? E:??
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
InformationStateString(0) = "??"
InformationStateString(1) = "??"
InformationStateTensor(0): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "??"
ObservationString(1) = "??"
ObservationTensor(0): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ChanceOutcomes() = [(0, 0.03571428571428571), (1, 0.03571428571428571), (3, 0.03571428571428571), (6, 0.03571428571428571), (10, 0.03571428571428571), (15, 0.03571428571428571), (21, 0.03571428571428571), (2, 0.03571428571428571), (4, 0.03571428571428571), (7, 0.03571428571428571), (11, 0.03571428571428571), (16, 0.03571428571428571), (22, 0.03571428571428571), (5, 0.03571428571428571), (8, 0.03571428571428571), (12, 0.03571428571428571), (17, 0.03571428571428571), (23, 0.03571428571428571), (9, 0.03571428571428571), (13, 0.03571428571428571), (18, 0.03571428571428571), (24, 0.03571428571428571), (14, 0.03571428571428571), (19, 0.03571428571428571), (25, 0.03571428571428571), (20, 0.03571428571428571), (26, 0.03571428571428571), (27, 0.03571428571428571)]
LegalActions() = [0, 1, 3, 6, 10, 15, 21, 2, 4, 7, 11, 16, 22, 5, 8, 12, 17, 23, 9, 13, 18, 24, 14, 19, 25, 20, 26, 27]
StringLegalActions() = ["HQHJ", "HKHJ", "HAHJ", "SJHJ", "SQHJ", "SKHJ", "SAHJ", "HKHQ", "HAHQ", "SJHQ", "SQHQ", "SKHQ", "SAHQ", "HAHK", "SJHK", "SQHK", "SKHK", "SAHK", "SJHA", "SQHA", "SKHA", "SAHA", "SQSJ", "SKSJ", "SASJ", "SKSQ", "SASQ", "SASK"]

# Apply action "SKHJ"
action: 15

# State 1
# W:SKHJ E:??
IsTerminal() = False
History() = [15]
HistoryString() = "15"
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
InformationStateString(0) = "SJHJ SJHK SJHQ SKHJ SKHK SKHQ SQHJ SQHK SQHQ"
InformationStateString(1) = "??"
InformationStateTensor(0): ◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "SJHJ SJHK SJHQ SKHJ SKHK SKHQ SQHJ SQHK SQHQ"
ObservationString(1) = "??"
ObservationTensor(0): ◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ChanceOutcomes() = [(2, 0.06666666666666667), (4, 0.06666666666666667), (7, 0.06666666666666667), (11, 0.06666666666666667), (22, 0.06666666666666667), (5, 0.06666666666666667), (8, 0.06666666666666667), (12, 0.06666666666666667), (23, 0.06666666666666667), (9, 0.06666666666666667), (13, 0.06666666666666667), (24, 0.06666666666666667), (14, 0.06666666666666667), (25, 0.06666666666666667), (26, 0.06666666666666667)]
LegalActions() = [2, 4, 7, 11, 22, 5, 8, 12, 23, 9, 13, 24, 14, 25, 26]
StringLegalActions() = ["HKHQ", "HAHQ", "SJHQ", "SQHQ", "SAHQ", "HAHK", "SJHK", "SQHK", "SAHK", "SJHA", "SQHA", "SAHA", "SQSJ", "SASJ", "SASQ"]

# Apply action "SQSJ"
action: 14

# State 2
# W:SKHJ E:SQSJ
IsTerminal() = False
History() = [15, 14]
HistoryString() = "15, 14"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "SJHJ SJHK SJHQ SKHJ SKHK SKHQ SQHJ SQHK SQHQ"
InformationStateString(1) = "SQSJ"
InformationStateTensor(0): ◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "SJHJ SJHK SJHQ SKHJ SKHK SKHQ SQHJ SQHK SQHQ"
ObservationString(1) = "SQSJ"
ObservationTensor(0): ◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5, 6]
StringLegalActions() = ["Pass", "1H", "1S", "1NT", "2H", "2S", "2NT"]

# Apply action "2S"
action: 5

# State 3
# W:SKHJ E:SQSJ 2S
IsTerminal() = False
History() = [15, 14, 5]
HistoryString() = "15, 14, 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "SJHJ SJHK SJHQ SKHJ SKHK SKHQ SQHJ SQHK SQHQ Us 2S"
InformationStateString(1) = "SQSJ Pd 2S"
InformationStateTensor(0): ◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯
InformationStateTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◉◯◯
ObservationString(0) = "SJHJ SJHK SJHQ SKHJ SKHK SKHQ SQHJ SQHK SQHQ 2S:Us"
ObservationString(1) = "SQSJ 2S:Pd"
ObservationTensor(0): ◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 6]
StringLegalActions() = ["Pass", "2NT"]

# Apply action "2NT"
action: 6

# State 4
# W:SKHJ E:SQSJ 2S-2NT
IsTerminal() = False
History() = [15, 14, 5, 6]
HistoryString() = "15, 14, 5, 6"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "SJHJ SJHK SJHQ SKHJ SKHK SKHQ SQHJ SQHK SQHQ Us 2S-2NT"
InformationStateString(1) = "SQSJ Pd 2S-2NT"
InformationStateTensor(0): ◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◉
InformationStateTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◉◉◯
ObservationString(0) = "SJHJ SJHK SJHQ SKHJ SKHK SKHQ SQHJ SQHK SQHQ 2NT:Pd"
ObservationString(1) = "SQSJ 2NT:Us"
ObservationTensor(0): ◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0]
StringLegalActions() = ["Pass"]

# Apply action "Pass"
action: 0

# State 5
# W:SKHJ E:SQSJ 2S-2NT-Pass
IsTerminal() = True
History() = [15, 14, 5, 6, 0]
HistoryString() = "15, 14, 5, 6, 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "SJHJ SJHK SJHQ SKHJ SKHK SKHQ SQHJ SQHK SQHQ Us 2S-2NT-Pass"
InformationStateString(1) = "SQSJ Pd 2S-2NT-Pass"
InformationStateTensor(0): ◯◯◯◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◉
InformationStateTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯◯◉◉◯
ObservationString(0) = "SJHJ SJHK SJHQ SKHJ SKHK SKHQ SQHJ SQHK SQHQ 2NT:Pd"
ObservationString(1) = "SQSJ 2NT:Us"
ObservationTensor(0): ◯◯◯◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◯◯
Rewards() = [-39.99999999999999, -39.99999999999999]
Returns() = [-39.99999999999999, -39.99999999999999]
